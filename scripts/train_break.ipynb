{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sgan.data.loader import data_loader\n",
    "from sgan.losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "from sgan.losses import displacement_error, final_displacement_error\n",
    "\n",
    "from sgan.models import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from sgan.utils import int_tuple, bool_flag, get_total_norm\n",
    "from sgan.utils import relative_to_abs, get_dset_path\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "FORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset_name', default='zara1', type=str)\n",
    "    parser.add_argument('--delim', default='\\t')\n",
    "    parser.add_argument('--loader_num_workers', default=4, type=int)\n",
    "    parser.add_argument('--obs_len', default=8, type=int)\n",
    "    parser.add_argument('--pred_len', default=8, type=int)\n",
    "    parser.add_argument('--skip', default=1, type=int)\n",
    "\n",
    "    # Optimization\n",
    "    parser.add_argument('--batch_size', default=64, type=int)\n",
    "    parser.add_argument('--num_iterations', default=10000, type=int)\n",
    "    parser.add_argument('--num_epochs', default=200, type=int)\n",
    "\n",
    "    # Model Options\n",
    "    parser.add_argument('--embedding_dim', default=64, type=int)\n",
    "    parser.add_argument('--num_layers', default=1, type=int)\n",
    "    parser.add_argument('--dropout', default=0, type=float)\n",
    "    parser.add_argument('--batch_norm', default=0, type=bool_flag)\n",
    "    parser.add_argument('--mlp_dim', default=1024, type=int)\n",
    "\n",
    "    # Generator Options\n",
    "    parser.add_argument('--encoder_h_dim_g', default=64, type=int)\n",
    "    parser.add_argument('--decoder_h_dim_g', default=128, type=int)\n",
    "    parser.add_argument('--noise_dim', default=8, type=int_tuple)\n",
    "    parser.add_argument('--noise_type', default='gaussian')\n",
    "    parser.add_argument('--noise_mix_type', default='ped')\n",
    "    parser.add_argument('--clipping_threshold_g', default=0, type=float)\n",
    "    parser.add_argument('--g_learning_rate', default=5e-4, type=float)\n",
    "    parser.add_argument('--g_steps', default=1, type=int)\n",
    "\n",
    "    # Pooling Options\n",
    "    parser.add_argument('--pooling_type', default='pool_net')\n",
    "    parser.add_argument('--pool_every_timestep', default=1, type=bool_flag)\n",
    "\n",
    "    # Pool Net Option\n",
    "    parser.add_argument('--bottleneck_dim', default=1024, type=int)\n",
    "\n",
    "    # Social Pooling Options\n",
    "    parser.add_argument('--neighborhood_size', default=2.0, type=float)\n",
    "    parser.add_argument('--grid_size', default=8, type=int)\n",
    "\n",
    "    # Discriminator Options\n",
    "    parser.add_argument('--d_type', default='local', type=str)\n",
    "    parser.add_argument('--encoder_h_dim_d', default=64, type=int)\n",
    "    parser.add_argument('--d_learning_rate', default=5e-4, type=float)\n",
    "    parser.add_argument('--d_steps', default=2, type=int)\n",
    "    parser.add_argument('--clipping_threshold_d', default=0, type=float)\n",
    "\n",
    "    # Loss Options\n",
    "    parser.add_argument('--l2_loss_weight', default=0, type=float)\n",
    "    parser.add_argument('--best_k', default=1, type=int)\n",
    "\n",
    "    # Output\n",
    "    parser.add_argument('--output_dir', default='break/')\n",
    "    parser.add_argument('--print_every', default=5, type=int)\n",
    "    parser.add_argument('--checkpoint_every', default=100, type=int)\n",
    "    parser.add_argument('--checkpoint_name', default='checkpoint')\n",
    "    parser.add_argument('--checkpoint_start_from', default=None)\n",
    "    parser.add_argument('--restore_from_checkpoint', default=1, type=int)\n",
    "    parser.add_argument('--num_samples_check', default=5000, type=int)\n",
    "\n",
    "    # Misc\n",
    "    parser.add_argument('--use_gpu', default=1, type=int)\n",
    "    parser.add_argument('--timing', default=0, type=int)\n",
    "    parser.add_argument('--gpu_num', default=\"0\", type=str)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype\n",
    "\n",
    "\n",
    "def discriminator_step(\n",
    "    args, batch, generator, discriminator, d_loss_fn, optimizer_d\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def generator_step(\n",
    "    args, batch, generator, discriminator, g_loss_fn, optimizer_g\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "\n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "        pred_traj_fake_rel = generator_out\n",
    "        pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "\n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(\n",
    "                loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    discriminator_loss = g_loss_fn(scores_fake)\n",
    "\n",
    "    loss += discriminator_loss\n",
    "    losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "    losses['G_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def check_accuracy(\n",
    "    args, loader, generator, discriminator, d_loss_fn, limit=False\n",
    "):\n",
    "    d_losses = []\n",
    "    metrics = {}\n",
    "    g_l2_losses_abs, g_l2_losses_rel = ([],) * 2\n",
    "    disp_error, disp_error_l, disp_error_nl = ([],) * 3\n",
    "    f_disp_error, f_disp_error_l, f_disp_error_nl = ([],) * 3\n",
    "    total_traj, total_traj_l, total_traj_nl = 0, 0, 0\n",
    "    loss_mask_sum = 0\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel,\n",
    "             non_linear_ped, loss_mask, seq_start_end) = batch\n",
    "            linear_ped = 1 - non_linear_ped\n",
    "            loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "            pred_traj_fake_rel = generator(\n",
    "                obs_traj, obs_traj_rel, seq_start_end\n",
    "            )\n",
    "            pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "            g_l2_loss_abs, g_l2_loss_rel = cal_l2_losses(\n",
    "                pred_traj_gt, pred_traj_gt_rel, pred_traj_fake,\n",
    "                pred_traj_fake_rel, loss_mask\n",
    "            )\n",
    "            ade, ade_l, ade_nl = cal_ade(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            fde, fde_l, fde_nl = cal_fde(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "            traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "            traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "            traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "            scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "            scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "            d_loss = d_loss_fn(scores_real, scores_fake)\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            g_l2_losses_abs.append(g_l2_loss_abs.item())\n",
    "            g_l2_losses_rel.append(g_l2_loss_rel.item())\n",
    "            disp_error.append(ade.item())\n",
    "            disp_error_l.append(ade_l.item())\n",
    "            disp_error_nl.append(ade_nl.item())\n",
    "            f_disp_error.append(fde.item())\n",
    "            f_disp_error_l.append(fde_l.item())\n",
    "            f_disp_error_nl.append(fde_nl.item())\n",
    "\n",
    "            loss_mask_sum += torch.numel(loss_mask.data)\n",
    "            total_traj += pred_traj_gt.size(1)\n",
    "            total_traj_l += torch.sum(linear_ped).item()\n",
    "            total_traj_nl += torch.sum(non_linear_ped).item()\n",
    "            if limit and total_traj >= args.num_samples_check:\n",
    "                break\n",
    "\n",
    "    metrics['d_loss'] = sum(d_losses) / len(d_losses)\n",
    "    metrics['g_l2_loss_abs'] = sum(g_l2_losses_abs) / loss_mask_sum\n",
    "    metrics['g_l2_loss_rel'] = sum(g_l2_losses_rel) / loss_mask_sum\n",
    "\n",
    "    metrics['ade'] = sum(disp_error) / (total_traj * args.pred_len)\n",
    "    metrics['fde'] = sum(f_disp_error) / total_traj\n",
    "    if total_traj_l != 0:\n",
    "        metrics['ade_l'] = sum(disp_error_l) / (total_traj_l * args.pred_len)\n",
    "        metrics['fde_l'] = sum(f_disp_error_l) / total_traj_l\n",
    "    else:\n",
    "        metrics['ade_l'] = 0\n",
    "        metrics['fde_l'] = 0\n",
    "    if total_traj_nl != 0:\n",
    "        metrics['ade_nl'] = sum(disp_error_nl) / (\n",
    "            total_traj_nl * args.pred_len)\n",
    "        metrics['fde_nl'] = sum(f_disp_error_nl) / total_traj_nl\n",
    "    else:\n",
    "        metrics['ade_nl'] = 0\n",
    "        metrics['fde_nl'] = 0\n",
    "\n",
    "    generator.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def cal_l2_losses(\n",
    "    pred_traj_gt, pred_traj_gt_rel, pred_traj_fake, pred_traj_fake_rel,\n",
    "    loss_mask\n",
    "):\n",
    "    g_l2_loss_abs = l2_loss(\n",
    "        pred_traj_fake, pred_traj_gt, loss_mask, mode='sum'\n",
    "    )\n",
    "    g_l2_loss_rel = l2_loss(\n",
    "        pred_traj_fake_rel, pred_traj_gt_rel, loss_mask, mode='sum'\n",
    "    )\n",
    "    return g_l2_loss_abs, g_l2_loss_rel\n",
    "\n",
    "\n",
    "def cal_ade(pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n",
    "    ade_l = displacement_error(pred_traj_fake, pred_traj_gt, linear_ped)\n",
    "    ade_nl = displacement_error(pred_traj_fake, pred_traj_gt, non_linear_ped)\n",
    "    return ade, ade_l, ade_nl\n",
    "\n",
    "\n",
    "def cal_fde(\n",
    "    pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "):\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n",
    "    fde_l = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], linear_ped\n",
    "    )\n",
    "    fde_nl = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], non_linear_ped\n",
    "    )\n",
    "    return fde, fde_l, fde_nl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: <ipython-input-4-5e5092f68767>:    8]: Initializing train dataset\n",
      "[INFO: <ipython-input-4-5e5092f68767>:   10]: Initializing val dataset\n",
      "[INFO: <ipython-input-4-5e5092f68767>:   18]: There are 21.03125 iterations per epoch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num\n",
    "train_path = get_dset_path(args.dataset_name, 'train')\n",
    "val_path = get_dset_path(args.dataset_name, 'val')\n",
    "\n",
    "long_dtype, float_dtype = get_dtypes(args)\n",
    "\n",
    "logger.info(\"Initializing train dataset\")\n",
    "train_dset, train_loader = data_loader(args, train_path)\n",
    "logger.info(\"Initializing val dataset\")\n",
    "_, val_loader = data_loader(args, val_path)\n",
    "\n",
    "iterations_per_epoch = len(train_dset) / args.batch_size / args.d_steps\n",
    "if args.num_epochs:\n",
    "    args.num_iterations = int(iterations_per_epoch * args.num_epochs)\n",
    "\n",
    "logger.info(\n",
    "    'There are {} iterations per epoch'.format(iterations_per_epoch)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: <ipython-input-35-eaabe45560dd>:   23]: Here is the generator:\n",
      "[INFO: <ipython-input-35-eaabe45560dd>:   24]: TrajectoryGenerator(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): LSTM(64, 128)\n",
      "    (pool_net): PoolHiddenNet(\n",
      "      (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (mlp_pre_pool): Sequential(\n",
      "        (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=1152, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (hidden2pos): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (pool_net): PoolHiddenNet(\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (mlp_pre_pool): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_decoder_context): Sequential(\n",
      "    (0): Linear(in_features=1088, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=120, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "[INFO: <ipython-input-35-eaabe45560dd>:   39]: Here is the discriminator:\n",
      "[INFO: <ipython-input-35-eaabe45560dd>:   40]: TrajectoryDiscriminator(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (real_classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = TrajectoryGenerator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    encoder_h_dim=args.encoder_h_dim_g,\n",
    "    decoder_h_dim=args.decoder_h_dim_g,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    noise_dim=(args.noise_dim,),\n",
    "    noise_type=args.noise_type,\n",
    "    noise_mix_type=args.noise_mix_type,\n",
    "    pooling_type=args.pooling_type,\n",
    "    pool_every_timestep=args.pool_every_timestep,\n",
    "    dropout=args.dropout,\n",
    "    bottleneck_dim=args.bottleneck_dim,\n",
    "    neighborhood_size=args.neighborhood_size,\n",
    "    grid_size=args.grid_size,\n",
    "    batch_norm=args.batch_norm)\n",
    "\n",
    "generator.apply(init_weights)\n",
    "generator.type(float_dtype).train()\n",
    "logger.info('Here is the generator:')\n",
    "logger.info(generator)\n",
    "\n",
    "discriminator = TrajectoryDiscriminator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    h_dim=args.encoder_h_dim_d,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    dropout=args.dropout,\n",
    "    batch_norm=args.batch_norm,\n",
    "    d_type=args.d_type)\n",
    "\n",
    "discriminator.apply(init_weights)\n",
    "discriminator.type(float_dtype).train()\n",
    "logger.info('Here is the discriminator:')\n",
    "logger.info(discriminator)\n",
    "\n",
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator.parameters(), lr=args.d_learning_rate\n",
    ")\n",
    "\n",
    "# Maybe restore from checkpoint\n",
    "restore_path = None\n",
    "if args.checkpoint_start_from is not None:\n",
    "    restore_path = args.checkpoint_start_from\n",
    "elif args.restore_from_checkpoint == 1:\n",
    "    restore_path = os.path.join(args.output_dir,\n",
    "                                '%s_with_model.pt' % args.checkpoint_name)\n",
    "\n",
    "if restore_path is not None and os.path.isfile(restore_path):\n",
    "    logger.info('Restoring from checkpoint {}'.format(restore_path))\n",
    "    checkpoint = torch.load(restore_path)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    discriminator.load_state_dict(checkpoint['d_state'])\n",
    "    optimizer_g.load_state_dict(checkpoint['g_optim_state'])\n",
    "    optimizer_d.load_state_dict(checkpoint['d_optim_state'])\n",
    "    t = checkpoint['counters']['t']\n",
    "    epoch = checkpoint['counters']['epoch']\n",
    "    checkpoint['restore_ts'].append(t)\n",
    "else:\n",
    "    # Starting from scratch, so initialize checkpoint data structure\n",
    "    t, epoch = 0, 0\n",
    "    checkpoint = {\n",
    "        'args': args.__dict__,\n",
    "        'G_losses': defaultdict(list),\n",
    "        'D_losses': defaultdict(list),\n",
    "        'losses_ts': [],\n",
    "        'metrics_val': defaultdict(list),\n",
    "        'metrics_train': defaultdict(list),\n",
    "        'sample_ts': [],\n",
    "        'restore_ts': [],\n",
    "        'norm_g': [],\n",
    "        'norm_d': [],\n",
    "        'counters': {\n",
    "            't': None,\n",
    "            'epoch': None,\n",
    "        },\n",
    "        'g_state': None,\n",
    "        'g_optim_state': None,\n",
    "        'd_state': None,\n",
    "        'd_optim_state': None,\n",
    "        'g_best_state': None,\n",
    "        'd_best_state': None,\n",
    "        'best_t': None,\n",
    "        'g_best_nl_state': None,\n",
    "        'd_best_state_nl': None,\n",
    "        'best_t_nl': None,\n",
    "    }\n",
    "t0 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while t < args.num_iterations:\n",
    "t = 1\n",
    "gc.collect()\n",
    "d_steps_left = args.d_steps\n",
    "g_steps_left = args.g_steps\n",
    "# epoch += 1\n",
    "# logger.info('Starting epoch {}'.format(epoch))\n",
    "for batch in train_loader:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = [tensor.cuda() for tensor in batch]\n",
    "(obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped, loss_mask, seq_start_end) = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 783, 2]) torch.Size([783, 16]) torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "print(obs_traj.shape, loss_mask.shape, seq_start_end.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 781,  783])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.any([0 in a for a in loss_mask]))\n",
    "seq_start_end[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 14.9392,   5.1551]),\n",
       " tensor([ 14.4998,   5.1551]),\n",
       " tensor([-0.4394,  0.0000]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_traj[0][1], obs_traj[1][1], obs_traj_rel[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        ...,\n",
       "        [ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False,  True],\n",
       "        [False, False],\n",
       "        ...,\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False,  True],\n",
       "        [False, False],\n",
       "        ...,\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False],\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        ...,\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        ...,\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]],\n",
       "\n",
       "       [[False, False],\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        ...,\n",
       "        [False, False],\n",
       "        [False, False],\n",
       "        [False, False]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(obs_traj_rel.tolist()) == np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
